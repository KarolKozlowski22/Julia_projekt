{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46053002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Code/1DI2153/RNN`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "X_train = load(\"../data/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../data/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../data/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../data/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "vocab = load(\"../data/imdb_dataset_prepared.jld2\", \"vocab\")\n",
    "embeddings = load(\"../data/imdb_dataset_prepared.jld2\", \"embeddings\")\n",
    "nothing\n",
    "\n",
    "embedding_dim = size(embeddings,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13aad85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Embedding(12849 => 50),               \u001b[90m# 642_450 parameters\u001b[39m\n",
       "  RNN(50 => 16, relu),                  \u001b[90m# 1_072 parameters\u001b[39m\n",
       "  var\"#1#2\"(),\n",
       "  Flux.flatten,\n",
       "  Dense(16 => 1, σ),                    \u001b[90m# 17 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m643_539 parameters, 2.455 MiB."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux, Random\n",
    "Random.seed!(0)\n",
    "\n",
    "model = Chain(\n",
    "    Flux.Embedding(length(vocab), embedding_dim),\n",
    "    Flux.RNN(embedding_dim => 16, relu, return_state = true),\n",
    "    x -> x[end],\n",
    "    Flux.flatten,\n",
    "    Dense(16, 1, σ)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b4a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Glove embeddings to Embedding layer\n",
    "model.layers[1].weight .= embeddings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2428538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (14.20s) \tTrain: (l: 0.69, a: 0.52) \tTest: (l: 0.69, a: 0.50)\n",
      "Epoch: 2 (4.99s) \tTrain: (l: 0.68, a: 0.54) \tTest: (l: 0.69, a: 0.51)\n",
      "Epoch: 3 (4.88s) \tTrain: (l: 0.57, a: 0.71) \tTest: (l: 0.55, a: 0.76)\n",
      "Epoch: 4 (5.09s) \tTrain: (l: 0.47, a: 0.79) \tTest: (l: 0.46, a: 0.79)\n",
      "Epoch: 5 (4.96s) \tTrain: (l: 0.41, a: 0.83) \tTest: (l: 0.43, a: 0.82)\n",
      "Epoch: 6 (5.09s) \tTrain: (l: 0.37, a: 0.85) \tTest: (l: 0.40, a: 0.83)\n",
      "Epoch: 7 (5.03s) \tTrain: (l: 0.34, a: 0.87) \tTest: (l: 0.83, a: 0.66)\n",
      "Epoch: 8 (5.34s) \tTrain: (l: 0.31, a: 0.88) \tTest: (l: 0.38, a: 0.84)\n",
      "Epoch: 9 (5.02s) \tTrain: (l: 0.28, a: 0.89) \tTest: (l: 0.37, a: 0.85)\n",
      "Epoch: 10 (5.24s) \tTrain: (l: 0.26, a: 0.91) \tTest: (l: 0.37, a: 0.85)\n",
      "Epoch: 11 (5.01s) \tTrain: (l: 0.24, a: 0.91) \tTest: (l: 0.37, a: 0.86)\n",
      "Epoch: 12 (5.08s) \tTrain: (l: 0.23, a: 0.92) \tTest: (l: 0.33, a: 0.87)\n"
     ]
    }
   ],
   "source": [
    "using Printf, Statistics\n",
    "\n",
    "dataset = Flux.DataLoader((X_train, y_train), batchsize=128, shuffle=true)\n",
    "\n",
    "loss(m, x, y) = Flux.Losses.binarycrossentropy(m(x), y)\n",
    "accuracy(m, x, y) = mean((m(x) .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "opt = Optimisers.setup(RMSProp(), model)\n",
    "\n",
    "epochs = 12\n",
    "for epoch in 1:epochs\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (x, y) in dataset\n",
    "            Flux.reset!(model)\n",
    "            grads = Flux.gradient(model) do m\n",
    "                loss(m, x, y)\n",
    "            end\n",
    "            Optimisers.update!(opt, model, grads[1])\n",
    "            total_loss += loss(model, x, y)\n",
    "            total_acc += accuracy(model, x, y)\n",
    "            num_samples += 1\n",
    "        end\n",
    "\n",
    "        train_loss = total_loss / num_samples\n",
    "        train_acc = total_acc / num_samples\n",
    "\n",
    "        test_acc = accuracy(model, X_test, y_test)\n",
    "        test_loss = loss(model, X_test, y_test)\n",
    "    end\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\", \n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa59ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
